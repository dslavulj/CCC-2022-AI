{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>i</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>h</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>i</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "      <td>i</td>\n",
       "      <td>d</td>\n",
       "      <td>f</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>g</td>\n",
       "      <td>...</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>h</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>h</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>g</td>\n",
       "      <td>h</td>\n",
       "      <td>g</td>\n",
       "      <td>...</td>\n",
       "      <td>c</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>h</td>\n",
       "      <td>g</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>g</td>\n",
       "      <td>h</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>h</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>g</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5453</th>\n",
       "      <td>d</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>i</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>g</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "      <td>i</td>\n",
       "      <td>e</td>\n",
       "      <td>g</td>\n",
       "      <td>h</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5454</th>\n",
       "      <td>h</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>h</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>i</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>g</td>\n",
       "      <td>e</td>\n",
       "      <td>g</td>\n",
       "      <td>g</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5455</th>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>g</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "      <td>h</td>\n",
       "      <td>b</td>\n",
       "      <td>h</td>\n",
       "      <td>g</td>\n",
       "      <td>i</td>\n",
       "      <td>e</td>\n",
       "      <td>i</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5456</th>\n",
       "      <td>b</td>\n",
       "      <td>i</td>\n",
       "      <td>g</td>\n",
       "      <td>d</td>\n",
       "      <td>g</td>\n",
       "      <td>a</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>i</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5457 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2  3  4  5  6  7  8  9   ... 20 21 22 23 24 25 26 27 28 29\n",
       "0     f  g  i  a  d  c  f  a  b  d  ...  e  f  e  e  c  i  e  d  c  b\n",
       "1     b  g  h  f  c  d  b  a  e  c  ...  e  i  c  i  h  d  c  c  b  e\n",
       "2     a  g  i  d  f  e  d  a  d  g  ...  c  d  b  a  h  g  c  d  e  h\n",
       "3     g  c  h  c  d  f  c  g  h  g  ...  c  f  c  d  e  c  f  g  b  g\n",
       "4     h  g  b  d  g  h  a  f  c  c  ...  c  a  g  c  d  f  c  b  b  e\n",
       "...  .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. ..\n",
       "5452  b  e  h  a  d  e  f  g  f  h  ...  b  a  a  f  a  i  g  c  g  d\n",
       "5453  d  f  f  f  i  e  h  c  c  e  ...  g  d  e  i  e  g  h  b  c  b\n",
       "5454  h  b  b  c  d  d  a  h  i  c  ...  b  i  b  b  e  g  e  g  g  e\n",
       "5455  c  a  c  i  a  b  g  d  d  g  ...  e  h  h  b  h  g  i  e  i  b\n",
       "5456  b  i  g  d  g  a  e  d  g  c  ...  b  b  e  i  e  d  e  f  e  c\n",
       "\n",
       "[5457 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"Data/training_data.csv\", names=[\"sequence\", \"class\"])\n",
    "train.head()\n",
    "X = train[\"sequence\"].apply(lambda x: pd.Series(list(x))).drop(columns=[30, 31, 32])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(X)\n",
    "X = enc.transform(X).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"Data/imbalanced_test_data.csv\", names=[\"sequence\", \"class\"])\n",
    "X_test = test[\"sequence\"].apply(lambda x: pd.Series(list(x)))\n",
    "X_test = enc.transform(X_test).toarray()\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5457\n",
      "6070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4856"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine  import SMOTETomek\n",
    "sm = SMOTE(random_state=42, k_neighbors=5)\n",
    "# sm = SMOTETomek(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, train[\"class\"])\n",
    "\n",
    "X_new_train, X_new_test, y_new_train, y_new_test = train_test_split(X_res, y_res, test_size=0.20, random_state=42, stratify=y_res)\n",
    "\n",
    "print(len(X))\n",
    "print(len(X_res))\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=y_new_train\n",
    ")\n",
    "len(classes_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.49109391028630045\n",
      "[21:27:21] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"sample_weight\", \"scale_pos_weight\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danij\\anaconda3\\envs\\CCC\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "C:\\Users\\danij\\anaconda3\\envs\\CCC\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       243\n",
      "           1       0.96      0.96      0.96       242\n",
      "           2       0.99      0.98      0.99       243\n",
      "           3       0.99      1.00      0.99       243\n",
      "           4       0.99      1.00      0.99       243\n",
      "\n",
      "    accuracy                           0.98      1214\n",
      "   macro avg       0.98      0.98      0.98      1214\n",
      "weighted avg       0.98      0.98      0.98      1214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "smallest_class_count = train[\"class\"].sum()\n",
    "largest_class_count = len(train[\"class\"]) - smallest_class_count\n",
    "spw = largest_class_count / smallest_class_count\n",
    "print(spw)\n",
    "\n",
    "clf = XGBClassifier(booster='gbtree', \n",
    "   \t\t\tobjective='multi:softmax',\n",
    "\t\t\tnum_class=5, \n",
    "\t\t\tlearning_rate=0.1, reg_alpha=0.005,\n",
    "  \t\t\tn_estimators=201, \n",
    "\t\t\tgamma = 0.8,\n",
    "\t\t\tsub_sample=0.1,\n",
    "\t\t\tcolsample_bytree=0.8,\n",
    "  \t\t\tscale_pos_weight=spw, \n",
    "  \t\t\trandom_state=101, \n",
    "            n_jobs=-1, \n",
    "\t\t\tsample_weight=classes_weights,\n",
    "\t\t\teval_metric=\"aucpr\")\n",
    "\n",
    "# clf.fit(X_new_train, y_new_train, sample_weight=classes_weights)\n",
    "clf.fit(X_new_train, y_new_train)\n",
    "# make predictions\n",
    "preds = clf.predict(X_new_test)\n",
    "target_names=[\"cls1\", \"cls2\", \"cls3\", \"cls4\", \"cls5\"]\n",
    "print(classification_report(y_new_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6070"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=y_res\n",
    ")\n",
    "len(classes_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_eval(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    err = 1-f1_score(y_true, np.round(y_pred))\n",
    "    return 'f1_err', err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.49109391028630045\n",
      "[21:27:28] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"sample_weight\", \"scale_pos_weight\", \"sub_sample\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danij\\anaconda3\\envs\\CCC\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "smallest_class_count = train[\"class\"].sum()\n",
    "largest_class_count = len(train[\"class\"]) - smallest_class_count\n",
    "spw = largest_class_count / smallest_class_count\n",
    "print(spw)\n",
    "\n",
    "bst =  XGBClassifier(booster='gbtree', \n",
    "   \t\t\tobjective='multi:softmax',\n",
    "\t\t\tnum_class=5, \n",
    "\t\t\tlearning_rate=0.1, reg_alpha=0.005,\n",
    "  \t\t\tn_estimators=201, \n",
    "\t\t\tgamma = 0.8,\n",
    "\t\t\tsub_sample=0.1,\n",
    "\t\t\tcolsample_bytree=0.8,\n",
    "  \t\t\tscale_pos_weight=spw, \n",
    "  \t\t\trandom_state=101, \n",
    "            n_jobs=-1, \n",
    "\t\t\tsample_weight=classes_weights,\n",
    "\t\t\teval_metric=\"aucpr\")\n",
    "\n",
    "\n",
    "bst.fit(X_res, y_res, sample_weight=classes_weights)\n",
    "# make predictions\n",
    "preds = bst.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"level_8_submission.csv\", \"a\")\n",
    "for i in preds.tolist():\n",
    "    f.write(str(i) + \"\\n\")\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "668189729e5ac70376e9665f53c2acda651dc4879c2cb2d545cf0be24cf593c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
